{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_Stacked_Autoencoders_to_Extract_Features_from_Data.ipynb","version":"0.3.2","provenance":[{"file_id":"1UO1GU3O9mSz9UexjLiNOOENQ_0s-b3SC","timestamp":1542122247850},{"file_id":"1iRuwyBpW_Ce4QWDHw0GirMyMN5Dusn3X","timestamp":1542118576095},{"file_id":"1sJA328dcutKrVTe4WvFARVMFZ8zX6_Wl","timestamp":1541971303237},{"file_id":"10T0p4FuaF4Bgph3dFRSYxbRMYkVPS9gN","timestamp":1541426296960},{"file_id":"1AzPfrMqrhUxgE8EN0WTPoJ39B5xIEx-a","timestamp":1541346109193},{"file_id":"1NEUvY8uKCaoht45hPQV_qOps7ZROw1l6","timestamp":1541264425550}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"KXCMLqVzKQ7F","colab_type":"text"},"cell_type":"markdown","source":["# Stacked Autoencoders to Extract Features from Data\n","\n","### Requirements\n","- Implement a deep fully-connected autoencoder for *BTC price differences data*\n","\n","- The size of autoencoder follows\n","  - first encoder layer: 40\n","  - second encoder layer: 30\n","  - encoding dim: 20\n","  - first decoder layer: 30\n","  - second decoder layer: 40\n","\n","\n","### Hints\n","- Refer Deep autoencoder from Hands-on-Labs\n","\n","\n","### Data Download at: https://drive.google.com/open?id=1_GXzTuyIopvkkOeCxHanVZKa0tKclD6F\n","\n","- Exercise. Stacked Autoencoders to Extract Features from Data"]},{"metadata":{"id":"gP7BoQO-Z6Wk","colab_type":"text"},"cell_type":"markdown","source":["# Data Preprocessing\n"]},{"metadata":{"id":"Us-FmgUYPjH9","colab_type":"text"},"cell_type":"markdown","source":["#### Procedures\n","- Preparation\n","  1. Unzip Data\n","\n","- Preprocessing\n","  1. Import Data\n","  2. Create Balanced Panel\n","  3. Train / Test Split "]},{"metadata":{"id":"EnRISOgoh5es","colab_type":"text"},"cell_type":"markdown","source":["## Preparation"]},{"metadata":{"id":"xIxPbmzGQFwR","colab_type":"text"},"cell_type":"markdown","source":["### 1. Data Import and Create Balanced Panel"]},{"metadata":{"id":"4T3G0OFBKcsJ","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TJVHhAmOMWmH","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"796JRrylMW2y","colab_type":"code","colab":{}},"cell_type":"code","source":["DATA_PATH = \"/content/gdrive/My Drive/Lecture/StudyPie/Data/CoinOne/\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"uV7aneomMlG6","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls \"/content/gdrive/My Drive/Lecture/StudyPie/Data/CoinOne/\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"cmkvrXr9MmQ6","colab_type":"code","colab":{}},"cell_type":"code","source":["# Unzip Data\n","# It will take more than 5 min\n","import zipfile\n","import io\n","\n","zf = zipfile.ZipFile(DATA_PATH+\"orderbook_data.zip\", \"r\")\n","zf.extractall(DATA_PATH)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b6KYwPnLrcT-","colab_type":"text"},"cell_type":"markdown","source":["### 2. Configurations"]},{"metadata":{"id":"7KTUsoWxNXqi","colab_type":"code","colab":{}},"cell_type":"code","source":["currency_types = [\"btc\"]\n","\n","TIME_FREQUENCY = 1 # 1, 2, 3, 30 minutes\n","TIME_SEQ_LEN = 200\n","\n","BATCH_SIZE = 64\n","NUM_ITERATIONS = 30\n","\n","TRAIN_RATIO = 0.8"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QI7dLsjor7-x","colab_type":"text"},"cell_type":"markdown","source":["## Preprocessing"]},{"metadata":{"id":"L7faHBekr9WE","colab_type":"text"},"cell_type":"markdown","source":["### 1. Import Data"]},{"metadata":{"id":"p2TejG4LMwkP","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","\n","# read coin price data\n","coin_price_dfs = pd.read_csv(DATA_PATH+\"coin_price_dfs.csv\")\n","\n","# sort by timestamp\n","coin_price_dfs = coin_price_dfs.sort_values(by=['timestamp','currency'])\n","\n","# select the columns of interests\n","coin_price_dfs = coin_price_dfs[coin_price_dfs[\"currency\"].isin(currency_types)]\n","\n","print(coin_price_dfs.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RdRbZCU-QRXL","colab_type":"text"},"cell_type":"markdown","source":["### 2. Create Balanced Panel"]},{"metadata":{"id":"HchnD0S5siCl","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","coinprice_features = ['currency','last', 'timestamp']\n","\n","panel_df = coin_price_dfs[coinprice_features]\n","\n","## interpolation\n","panel_df = panel_df.groupby('currency').apply(lambda gp: gp.fillna(method=\"ffill\"))\n","\n","panel_df = panel_df.groupby((panel_df.timestamp / (TIME_FREQUENCY)).astype('int')).agg({\n","                                                            u'currency': 'last',\n","                                                            u'timestamp': 'last',\n","                                                            u'last':'last'})\n","\n","\n","panel_df['last'] = panel_df['last'] - panel_df['last'].shift(1)\n","panel_df.rename(columns={'last':'last_differences'}, inplace=True)\n","\n","panel_df.dropna(inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vV5_iF7Asj5U","colab_type":"code","colab":{}},"cell_type":"code","source":["panel_df[panel_df['currency']=='btc'].head(n=5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JqnfXndEuSiH","colab_type":"text"},"cell_type":"markdown","source":["### 3. Train / Test Split"]},{"metadata":{"id":"82UhUhYSuUle","colab_type":"code","colab":{}},"cell_type":"code","source":["# split train test dataset\n","panel_df_train = panel_df.iloc[:int(panel_df.shape[0]*TRAIN_RATIO)]\n","panel_df_test = panel_df[~panel_df.index.isin(panel_df_train.index)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hoZe70p8kJQr","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import random\n","from collections import deque\n","\n","def sequence_generator(panel_df, TIME_SEQ_LEN, suffle=True,seed=101):\n","\n","  sequential_data = []  # this is a list that will CONTAIN the sequences\n","  queue = deque(maxlen = TIME_SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n","\n","  for i in panel_df['last_differences'].tolist():  # iterate over the values\n","    queue.append(i)  # store all but the target\n","    if len(queue) == TIME_SEQ_LEN:  # make sure we have 60 sequences!\n","      sequential_data.append(np.array(queue))  # append those bad boys!\n","\n","  if suffle == True:\n","    random.seed(seed)\n","    random.shuffle(sequential_data)  # shuffle for good measure.\n","    \n","  return np.array(sequential_data), np.array(sequential_data) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"Wt-VtzACi9Y6","colab_type":"code","colab":{}},"cell_type":"code","source":["train_X, train_Y = sequence_generator(panel_df_train, TIME_SEQ_LEN, suffle=True, seed=101)\n","test_X, test_Y = sequence_generator(panel_df_test, TIME_SEQ_LEN, suffle=False)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BmlBY2nElQOl","colab_type":"code","colab":{}},"cell_type":"code","source":["print(train_X.shape)\n","print(test_X.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5EUZ0DaTvPg4","colab_type":"text"},"cell_type":"markdown","source":["# Exercise Stacked Autoencoders to Extract Features from Data"]},{"metadata":{"id":"RHjlJ1Kcu48a","colab_type":"text"},"cell_type":"markdown","source":["# Stacked Autoencoders to Extract Features from Data\n","\n","### Requirements\n","- Implement a deep fully-connected autoencoder for *BTC price differences data*\n","\n","- The size of autoencoder follows\n","  - first encoder layer: 40\n","  - second encoder layer: 30\n","  - encoding dim: 20\n","  - first decoder layer: 30\n","  - second decoder layer: 40\n","\n","\n","### Hints\n","- Refer Deep autoencoder from Hands-on-Labs\n","\n","\n","### Data Download at: https://drive.google.com/open?id=1_GXzTuyIopvkkOeCxHanVZKa0tKclD6F\n","\n","- Exercise. Stacked Autoencoders to Extract Features from Data"]},{"metadata":{"id":"x_JZcMKHh9xV","colab_type":"text"},"cell_type":"markdown","source":["### 1. Model Build"]},{"metadata":{"id":"0bADWJMbvhfj","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense\n","\n","def autoencoder_model(input_dim, output_dim):\n","  \n","  \"\"\"\n","  Write Code Here!!!!\n","  \n","  \"\"\"\n","\n","  return autoencoder"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2xtMiiEMiJ-N","colab_type":"code","colab":{}},"cell_type":"code","source":["model_dict = {}\n","model_dict[\"AE\"] = autoencoder_model(train_X.shape[1], train_Y.shape[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8xHSWzs8iBq1","colab_type":"text"},"cell_type":"markdown","source":["### 2. Model Train\n"]},{"metadata":{"id":"XlwicNBhiFSt","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 128\n","NUM_ITERATIONS = 1000\n","\n","hist = {}\n","\n","for name, model in model_dict.items():\n","\n","  print(\"===== Model Name: {} =====\".format(name))\n","  if name == \"AE\":\n","    hist[name] = model.fit(train_X, train_Y, \n","                            batch_size = BATCH_SIZE,\n","                            validation_split=0.2,\n","                            epochs = NUM_ITERATIONS)\n","\n","  print(\"===== Train Done =====\".format(name))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Sjk0WzkeiDV9","colab_type":"text"},"cell_type":"markdown","source":["### 3. Prediction"]},{"metadata":{"id":"IZS3dLzDiEjk","colab_type":"code","colab":{}},"cell_type":"code","source":["predictions = {}\n","\n","for name, model in model_dict.items():  \n","  print(\"===== Model Name: {} =====\".format(name))  \n","  if name == \"AE\":\n","    predictions[name] = model.predict(test_X)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gpMXFCmJWpGn","colab_type":"text"},"cell_type":"markdown","source":["### 4. Evaluation"]},{"metadata":{"id":"W4fg4LpdrNwp","colab_type":"text"},"cell_type":"markdown","source":["1. Comparing Accuracy both Train and Validation set data\n","  - Compare loss according to the below materials\n","  - Visualize training history  \n","  - Check genelarization of your model\n","  - Refer\n","    - https://medium.com/machine-learning-world/neural-networks-for-algorithmic-trading-1-2-correct-time-series-forecasting-backtesting-9776bfd9e589\n","  - Visualization Hint\n","    - https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"]},{"metadata":{"id":"vyS_lAOOrJYm","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.title('model loss')\n","legend_names = []\n","# summarize history for accuracy\n","for name, model_hist in hist.items():\n","  plt.plot(model_hist.history['loss'])\n","  plt.plot(model_hist.history['val_loss'])\n","  legend_names.extend([name+'_train', name+'_validation'])\n","  \n","plt.legend(legend_names, loc='upper left')\n","\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FJLMnCarxKuf","colab_type":"text"},"cell_type":"markdown","source":["2. True Price vs. Generate Price\n"]},{"metadata":{"id":"ru67SM1hxKVW","colab_type":"code","colab":{}},"cell_type":"code","source":["for name, prediction_model in predictions.items():\n","  print(\"===== Model Name: {} =====\".format(name))\n","  \n","  for _ in range(3):\n","    i = np.random.choice(len(prediction_model))\n","    plt.plot(prediction_model[i], label = name+' generated price differences')    \n","    plt.plot(test_Y[i], label = 'true price differences')\n","    plt.xticks(rotation=30)\n","    plt.legend()\n","    plt.show()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ESKvBXTcpYB3","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}