{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_Measure_Performance_of_Your_Own_Neural_Network_Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "KXCMLqVzKQ7F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Measure Performance of Your Own Neural Network Model\n",
        "\n",
        "This is continual series of assigment \n",
        "\n",
        "You can extend your own code from asssigment M3.1\n",
        "\n",
        "#### Note. I changed the previous criteria for significant increase / decrease into 0.2 std from 1.0 std to avoid the safe answer\n",
        "\n",
        "- Exercise1 Performance Evaluation for Trinary Classification Model\n",
        "- Exercise2 Performance Evaluation for Return Prediction Model"
      ]
    },
    {
      "metadata": {
        "id": "gP7BoQO-Z6Wk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercise1  Performance Evaluation for Trinary Classification Model\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Us-FmgUYPjH9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Download at: https://drive.google.com/open?id=1thjGhgnAm5k1zuSiWhGmlUJzBXM3IECi\n",
        "\n",
        "This exercise is a little bit long exercise, that should give you an idea of a real world scenario. Feel free to look at the solution if you feel lost.\n",
        "\n",
        "#### Requirements\n",
        "1. Comparing Accuracy for both Train and Validation set data\n",
        "  - Compare accurcacy according to the below materials\n",
        "  - Visualize training history  \n",
        "  - Check genelarization of your model\n",
        "  - Refer\n",
        "    - https://medium.com/machine-learning-world/neural-networks-for-algorithmic-trading-1-2-correct-time-series-forecasting-backtesting-9776bfd9e589\n",
        "  - Visualization Hint\n",
        "    - https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "    \n",
        "2. Measure Model Accuracy for Classification Problem\n",
        "  -  Now we are going to evaluate our model \n",
        "  - Accuracy, Recall, F1 Score based on Confusion Matrix\n",
        "  - Refer definition of each scores\n",
        "    - Confusion matrix https://en.wikipedia.org/wiki/Confusion_matrix\n",
        "    - Confusion matrix in Korean https://datascienceschool.net/view-notebook/731e0d2ef52c41c686ba53dcaf346f32/\n",
        "  - Hint\n",
        "    - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "    - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "    \n",
        "3. Measure Test Set Return based on the Simplest Strategy\n",
        "  - Condition\n",
        "    - Initial budget = 100\n",
        "  - Strategy\n",
        "    - If we predict up, then buy or hold (if we already bought)\n",
        "    - If we predict down or no change then sell (if we already bought) or do nothing \n",
        "  - Draw your return\n",
        "\n",
        "#### Procedures\n",
        "- Preprocessing\n",
        "  1. Data Import and Create Balanced Panel\n",
        "  2. Create Target Variable\n",
        "  3. Train / Test Split\n",
        "  4. Create Sequences\n",
        "\n",
        "- Training / Predicting Model\n",
        "  1. Model Build\n",
        "  2. Model Train\n",
        "  3. Prediction\n",
        "  4. Evaluation <- this assignment implement it"
      ]
    },
    {
      "metadata": {
        "id": "EnRISOgoh5es",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "xIxPbmzGQFwR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Data Import and Create Balanced Panel"
      ]
    },
    {
      "metadata": {
        "id": "4T3G0OFBKcsJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJVHhAmOMWmH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "796JRrylMW2y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/gdrive/My Drive/Lecture/StudyPie/Data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uV7aneomMlG6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/My Drive/Lecture/StudyPie/Data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cmkvrXr9MmQ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Unzip Data\n",
        "# It will take more than 5 min\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "zf = zipfile.ZipFile(DATA_PATH+\"crypto_data.zip\", \"r\")\n",
        "zf.extractall(DATA_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7KTUsoWxNXqi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 60  # how long of a preceeding sequence to collect for RNN\n",
        "FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
        "RATIO_TO_PREDICT = \"LTC-USD\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p2TejG4LMwkP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "main_df = pd.DataFrame() # begin empty\n",
        "\n",
        "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]  # the 4 ratios we want to consider\n",
        "\n",
        "for ratio in ratios:  # begin iteration\n",
        "    print(ratio)\n",
        "    dataset = DATA_PATH+f'crypto_data/{ratio}.csv'  # get the full path to the file.\n",
        "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])  # read in specific file\n",
        "\n",
        "    # rename volume and close to include the ticker so we can still which close/volume is which:\n",
        "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True)\n",
        "\n",
        "    df.set_index(\"time\", inplace=True)  # set time as index so we can join them on this shared time\n",
        "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]  # ignore the other columns besides price and volume\n",
        "\n",
        "    if len(main_df)==0:  # if the dataframe is empty\n",
        "        main_df = df  # then it's just the current df\n",
        "    else:  # otherwise, join this data to the main one\n",
        "        main_df = main_df.join(df)\n",
        "\n",
        "main_df.fillna(method=\"ffill\", inplace=True)  # if there are gaps in data, use previously known values\n",
        "main_df.dropna(inplace=True)\n",
        "print(main_df.head())  # how did we do??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RdRbZCU-QRXL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Create Target Variable"
      ]
    },
    {
      "metadata": {
        "id": "yBLQ8fpSM0My",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SIGNIFICANT_CRITERIA = 0.2   # 0.2 std criteria \n",
        "\n",
        "currency_targets = [\"BTC\"]\n",
        "\n",
        "for currency_target in currency_targets:\n",
        "    main_df[currency_target+'-USD-TARGET'] = main_df[currency_target+'-USD_close'].shift(-FUTURE_PERIOD_PREDICT )\n",
        "    main_df[currency_target+'-USD-TARGET-RETURN'] = (main_df[currency_target+'-USD-TARGET'] \n",
        "                                                                - main_df[currency_target+'-USD_close'])/main_df[currency_target+'-USD_close']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rm5Fw5iJjTtW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def classify_trinary(values):\n",
        "    gp_std = np.std(values)\n",
        "\n",
        "    target = []\n",
        "    for value in values:\n",
        "        if SIGNIFICANT_CRITERIA*gp_std < value: # significant increase\n",
        "            target.append(2)\n",
        "        elif -SIGNIFICANT_CRITERIA*gp_std > value:  # significant decrease\n",
        "            target.append(0)  \n",
        "        else:\n",
        "            target.append(1) # No significant change\n",
        "            \n",
        "    return target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pgbWDf51pisa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gSNeN1bRjVVm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for currency_target in currency_targets:\n",
        "    print(\"SIGNIFICANT_CRITERIA:\", SIGNIFICANT_CRITERIA)\n",
        "    main_df[currency_target+'-TARGET'] = main_df[currency_target+'-USD-TARGET-RETURN'].transform(classify_trinary)\n",
        "    main_df.drop(columns=[currency_target+'-USD-TARGET', currency_target+'-USD-TARGET-RETURN'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfzqBWw5ky7J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fxLoFPleQT2t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Train / Test Split"
      ]
    },
    {
      "metadata": {
        "id": "0arExbjMNN--",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "times = sorted(main_df.index.values)  # get the times\n",
        "last_5pct = sorted(main_df.index.values)[-int(0.05*len(times))]  # get the last 5% of the times\n",
        "\n",
        "test_main_df = main_df[(main_df.index >= last_5pct)]  # make the validation data where the index is in the last 5%\n",
        "main_df = main_df[(main_df.index < last_5pct)]  # now the main_df is all the data up to the last 5%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cP190OkbQV_p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Create Sequences"
      ]
    },
    {
      "metadata": {
        "id": "tiaXUZ-JNnA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing  # pip install sklearn ... if you don't have it!\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def sequence_generator(main_df, SEQ_LEN, suffle=True,seed=101):\n",
        "    \n",
        "  sequential_data = []  # this is a list that will CONTAIN the sequences\n",
        "  queue = deque(maxlen = SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
        "\n",
        "  for i in main_df.values:  # iterate over the values\n",
        "      queue.append([n for n in i[:-1]])  # store all but the target\n",
        "      if len(queue) == SEQ_LEN:  # make sure we have 60 sequences!\n",
        "          sequential_data.append([np.array(queue), i[-1]])  # append those bad boys!\n",
        "\n",
        "  if suffle == True:\n",
        "      random.seed(seed)\n",
        "      random.shuffle(sequential_data)  # shuffle for good measure.\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for seq, target in sequential_data:  # going over our new sequential data\n",
        "      X.append(seq)  # X is the sequences\n",
        "      y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
        "\n",
        "  return np.array(X), y  # return X and y...and make X a numpy array!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kShgSiKgN9sA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x, train_y = sequence_generator(main_df , SEQ_LEN, suffle=True, seed=101)\n",
        "test_x, test_y = sequence_generator(test_main_df , SEQ_LEN, suffle=True, seed=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nkn_cv6wPVEA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_x.shape, len(train_y))\n",
        "print(test_x.shape, len(test_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YO3VoIQFh8ce",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Up/ No Significant Change / Down Prediction Model"
      ]
    },
    {
      "metadata": {
        "id": "x_JZcMKHh9xV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Model Build"
      ]
    },
    {
      "metadata": {
        "id": "SqcfJrxmiFpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization, Flatten\n",
        "\n",
        "def ex1_models(input_dim, output_dim):\n",
        "\n",
        "  # you can try your own model!\n",
        "\n",
        "  L1 = 50  # 30\n",
        "  L2 = 30  # 20\n",
        "  L3 = 20  # 10\n",
        "  L4 = 10  # 5\n",
        "  L5 = 5\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(L1, input_shape=input_dim, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(L2, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(L3, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(L4, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(L5, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "    \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2xtMiiEMiJ-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1 = ex1_models(train_x.shape[1:], 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8xHSWzs8iBq1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Model Train\n"
      ]
    },
    {
      "metadata": {
        "id": "XlwicNBhiFSt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64 \n",
        "NUM_ITERATIONS = 10\n",
        "\n",
        "hist1 = model1.fit(train_x, tf.keras.utils.to_categorical(train_y, num_classes=None), \n",
        "              validation_split=0.2,\n",
        "              batch_size = BATCH_SIZE,\n",
        "              epochs = NUM_ITERATIONS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sjk0WzkeiDV9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Prediction"
      ]
    },
    {
      "metadata": {
        "id": "IZS3dLzDiEjk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model1.predict_classes(test_x)\n",
        "\n",
        "# Score model\n",
        "score = model1.evaluate(test_x, tf.keras.utils.to_categorical(test_y, num_classes=None), \n",
        "                       verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8PT5YHk4Wl-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "JeE6WQZMWm4M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Comparing Accuracy for both Train and Validation set data\n",
        "  - Compare accurcacy according to the below materials\n",
        "  - Visualize training history\n",
        "  - Check genelarization of your model\n",
        "  - Refer\n",
        "    - https://medium.com/machine-learning-world/neural-networks-for-algorithmic-trading-1-2-correct-time-series-forecasting-backtesting-9776bfd9e589\n",
        "  - Visualization Hint\n",
        "    - https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/    "
      ]
    },
    {
      "metadata": {
        "id": "DXqPmkyP0Gu1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(hist1.history.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-1WxmoimbwXp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cGljPRxdbwmK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. Measure Model Accuracy for Classification Problem\n",
        "  -  Now we are going to evaluate our model \n",
        "  - Accuracy, Recall, F1 Score based on Confusion Matrix\n",
        "  - Refer definition of each scores\n",
        "    - Confusion matrix https://en.wikipedia.org/wiki/Confusion_matrix\n",
        "    - Confusion matrix in Korean https://datascienceschool.net/view-notebook/731e0d2ef52c41c686ba53dcaf346f32/\n",
        "  - Hint\n",
        "    - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "    - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
      ]
    },
    {
      "metadata": {
        "id": "vbZvAFJfbw7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4R8KqNAfbxEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. Measure Test Set Return based on the Simplest Strategy\n",
        "  - Condition\n",
        "    - Initial budget = 100\n",
        "  - Strategy\n",
        "    - If we predict up, then buy or hold (if we already bought)\n",
        "    - If we predict down or no change then sell (if we already bought) or do nothing \n",
        "  - Draw your return\n"
      ]
    },
    {
      "metadata": {
        "id": "oG34yv5hbxND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qfM3kZifnK-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercise2 Performance Evaluation for Return Prediction Model\n",
        "\n",
        "#### Requirements\n",
        "1. Comparing loss for both Train and Validation set data\n",
        "  - Compare loss according to the below materials\n",
        "  - Visualize training history  \n",
        "  - Check genelarization of your model\n",
        "  - Refer\n",
        "    - https://medium.com/machine-learning-world/neural-networks-for-algorithmic-trading-1-2-correct-time-series-forecasting-backtesting-9776bfd9e589\n",
        "  - Visualization Hint\n",
        "    - https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "    \n",
        "2. Measure Model Accuracy for Continuous Value\n",
        "  - Change Your Prediction Values into Up / Down Binary Variable\n",
        "  - After then do the same things as in Exercise 1\n",
        "    - Accuracy, Recall, F1 Score based on Confusion Matrix\n",
        "    - Refer definition of each scores\n",
        "      - Confusion matrix https://en.wikipedia.org/wiki/Confusion_matrix\n",
        "      - Confusion matrix in Korean https://datascienceschool.net/view-notebook/731e0d2ef52c41c686ba53dcaf346f32/\n",
        "  - Hint\n",
        "    - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "    - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
        "    \n",
        "3. Measure Test Set Return based on the Simplest Strategy\n",
        "  - Condition\n",
        "    - Initial budget = 100\n",
        "  - Strategy\n",
        "    - If we predict up, then buy or hold (if we already bought)\n",
        "    - If we predict down, then sell (if we already bought) or do nothing \n",
        "  - Draw your return\n",
        "\n",
        "#### Procedures\n",
        "- Preprocessing\n",
        "  1. Data Import and Create Balanced Panel\n",
        "  2. Create Target Variable\n",
        "  3. Train / Test Split\n",
        "  4. Create Sequences\n",
        "  \n",
        "- Training / Predicting Model\n",
        "  1. Model Build\n",
        "  2. Model Train\n",
        "  3. Prediction\n",
        "  4. Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "ey7GAk22nm1T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 60  # how long of a preceeding sequence to collect for RNN\n",
        "FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
        "RATIO_TO_PREDICT = \"LTC-USD\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m7vQBLJZq7j7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "754AjNC3q97y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Data Import and Create Balanced Panel"
      ]
    },
    {
      "metadata": {
        "id": "ooR6vTP7q1LP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing \n",
        "\n",
        "main_df = pd.DataFrame() # begin empty\n",
        "\n",
        "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]  # the 4 ratios we want to consider\n",
        "\n",
        "for ratio in ratios:  # begin iteration\n",
        "  print(ratio)\n",
        "  dataset = DATA_PATH+f'crypto_data/{ratio}.csv'  # get the full path to the file.\n",
        "  df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])  # read in specific file\n",
        "\n",
        "  # rename volume and close to include the ticker so we can still which close/volume is which:\n",
        "  df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True)\n",
        "\n",
        "  df.set_index(\"time\", inplace=True)  # set time as index so we can join them on this shared time\n",
        "  df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]  # ignore the other columns besides price and volume\n",
        "\n",
        "  if len(main_df)==0:  # if the dataframe is empty\n",
        "      main_df = df  # then it's just the current df\n",
        "  else:  # otherwise, join this data to the main one\n",
        "      main_df = main_df.join(df)\n",
        "\n",
        "main_df.fillna(method=\"ffill\", inplace=True)  # if there are gaps in data, use previously known values\n",
        "main_df.dropna(inplace=True)\n",
        "print(main_df.head())  # how did we do??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aT2FA6Qzq4ev",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Create Target Variable"
      ]
    },
    {
      "metadata": {
        "id": "QzAsHZIxq3rv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "currency_targets = [\"BTC\"]\n",
        "\n",
        "for currency_target in currency_targets:\n",
        "  main_df[currency_target+'-USD-TARGET'] = main_df[currency_target+'-USD_close'].shift(-FUTURE_PERIOD_PREDICT )\n",
        "\n",
        "  # scale up, you can do any other scaling methods!\n",
        "  # how can we improve this part?\n",
        "  # hint: reduce noise of future return\n",
        "  main_df[currency_target+'-USD-TARGET-RETURN'] = (main_df[currency_target+'-USD-TARGET']-main_df[currency_target+'-USD_close'])/main_df[currency_target+'-USD_close']*100\n",
        "  \n",
        "  main_df.drop(columns=[currency_target+'-USD-TARGET'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7gA78XCvzUJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing  # pip install sklearn ... if you don't have it!\n",
        "\n",
        "# Scaling Your Data\n",
        "main_df.fillna(main_df.mean(), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UtIx1zn1rEQ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73dbkD2wrUCM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Train / Test Split"
      ]
    },
    {
      "metadata": {
        "id": "hdBJZalyrQBs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "times = sorted(main_df.index.values)  # get the times\n",
        "last_5pct = sorted(main_df.index.values)[-int(0.05*len(times))]  # get the last 5% of the times\n",
        "\n",
        "test_main_df = main_df[(main_df.index >= last_5pct)]  # make the validation data where the index is in the last 5%\n",
        "main_df = main_df[(main_df.index < last_5pct)]  # now the main_df is all the data up to the last 5%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hhupZQWGrXYs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Create Sequences"
      ]
    },
    {
      "metadata": {
        "id": "1nZZOqKkrZ-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing  # pip install sklearn ... if you don't have it!\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def sequence_generator(main_df, SEQ_LEN, suffle=True,seed=101):\n",
        "    \n",
        "  sequential_data = []  # this is a list that will CONTAIN the sequences\n",
        "  queue = deque(maxlen = SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
        "\n",
        "  for i in main_df.values:  # iterate over the values\n",
        "      queue.append([n for n in i[:-1]])  # store all but the target\n",
        "      if len(queue) == SEQ_LEN:  # make sure we have 60 sequences!\n",
        "          sequential_data.append([np.array(queue), i[-1]])  # append those bad boys!\n",
        "\n",
        "  if suffle == True:\n",
        "      random.seed(seed)\n",
        "      random.shuffle(sequential_data)  # shuffle for good measure.\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for seq, target in sequential_data:  # going over our new sequential data\n",
        "      X.append(seq)  # X is the sequences\n",
        "      y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
        "\n",
        "  return np.array(X), y  # return X and y...and make X a numpy array!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WMPS0r6grcFs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x, train_y = sequence_generator(main_df , SEQ_LEN, suffle=True, seed=101)\n",
        "test_x, test_y = sequence_generator(test_main_df , SEQ_LEN, suffle=True, seed=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NBTVnFZhrd5z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_x.shape, len(train_y))\n",
        "print(test_x.shape, len(test_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4Wp-Efxrfoz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Return Prediction Model"
      ]
    },
    {
      "metadata": {
        "id": "ZppjdkQmrjcD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Model Build"
      ]
    },
    {
      "metadata": {
        "id": "7UNi3N9SryVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM,\\\n",
        "CuDNNLSTM, BatchNormalization, Flatten, Activation\n",
        "\n",
        "def ex2_models(input_dim, output_dim):\n",
        "\n",
        "  # you can try your own model!\n",
        "  \n",
        "  L1 = 256  # 256\n",
        "  L2 = 256  # 256\n",
        "  L3 = 32  # 32\n",
        "\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(CuDNNLSTM(L1, input_shape=input_dim, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
        "\n",
        "  model.add(CuDNNLSTM(L2, return_sequences=True))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(CuDNNLSTM(L3))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(output_dim))\n",
        "  model.add(Activation('linear'))\n",
        "  \n",
        "  model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "            loss='mean_squared_error')\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dw-1hJa0rppx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Model Train"
      ]
    },
    {
      "metadata": {
        "id": "skDP-L25rx8-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2 = ex2_models(train_x.shape[1:], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yP0GWYGar_RW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64 \n",
        "NUM_ITERATIONS = 10\n",
        "\n",
        "hist2 = model2.fit(train_x, train_y,\n",
        "              validation_split=0.2,\n",
        "              batch_size = BATCH_SIZE,\n",
        "              epochs = NUM_ITERATIONS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUWrOqQfrvlY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Prediction"
      ]
    },
    {
      "metadata": {
        "id": "rrp4PaUvrxPZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model2.predict(test_x)\n",
        "\n",
        "# Score model\n",
        "score = model2.evaluate(test_x, test_y,\n",
        "                       verbose=0)\n",
        "\n",
        "print('Test loss:', score) # this is mean_squared_error "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W4wWyk7nzFwL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "XKQMt0ZFWhRR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Comparing Loss for both Train and Validation set data\n",
        "  - Compare loss according to the below materials\n",
        "  - Visualize training history  \n",
        "  - Check genelarization of your model\n",
        "  - Refer\n",
        "    - https://medium.com/machine-learning-world/neural-networks-for-algorithmic-trading-1-2-correct-time-series-forecasting-backtesting-9776bfd9e589\n",
        "  - Visualization Hint\n",
        "    - https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/    "
      ]
    },
    {
      "metadata": {
        "id": "FaVyRjhl4NoC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(hist2.history.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2L-rNta0b5ya",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TPt6VniAb6Mz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "    \n",
        "2. Measure Model Accuracy for Continuous Value\n",
        "  - Change Your Prediction Values into Up / Down Binary Variable\n",
        "  - After then do the same things as in Exercise 1\n",
        "    - Accuracy, Recall, F1 Score based on Confusion Matrix\n",
        "    - Refer definition of each scores\n",
        "      - Confusion matrix https://en.wikipedia.org/wiki/Confusion_matrix\n",
        "      - Confusion matrix in Korean https://datascienceschool.net/view-notebook/731e0d2ef52c41c686ba53dcaf346f32/\n",
        "  - Hint\n",
        "    - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "    - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
      ]
    },
    {
      "metadata": {
        "id": "YNRjEnUWb7jq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z5J3v3Vgb70i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3. Measure Test Set Return based on the Simplest Strategy\n",
        "  - Condition\n",
        "    - Initial budget = 100\n",
        "  - Strategy\n",
        "    - If we predict up, then buy or hold (if we already bought)\n",
        "    - If we predict down, then sell (if we already bought) or do nothing \n",
        "  - Draw your return\n"
      ]
    },
    {
      "metadata": {
        "id": "amHohL_Tb9FB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}