{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_CNN_Encoder_LSTM_with_Orderbook_Data.ipynb","version":"0.3.2","provenance":[{"file_id":"1XJ18u6j_3i8MlXtnkszujwwx5d4RL9eQ","timestamp":1542062009812},{"file_id":"1iRuwyBpW_Ce4QWDHw0GirMyMN5Dusn3X","timestamp":1542061697319},{"file_id":"1sJA328dcutKrVTe4WvFARVMFZ8zX6_Wl","timestamp":1541971303237},{"file_id":"10T0p4FuaF4Bgph3dFRSYxbRMYkVPS9gN","timestamp":1541426296960},{"file_id":"1AzPfrMqrhUxgE8EN0WTPoJ39B5xIEx-a","timestamp":1541346109193},{"file_id":"1NEUvY8uKCaoht45hPQV_qOps7ZROw1l6","timestamp":1541264425550}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"KXCMLqVzKQ7F","colab_type":"text"},"cell_type":"markdown","source":["# CNN Encoder + RNN Time Series Prediction Model with Limit Orderbook Data\n","\n","## Read About Timedistributed Layer\n","https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n","\n","### Requirements\n","- Implement Your Own CNN Encoder +  LSTM Model for Trinary Classification Model\n","\n","### Data Download at: https://drive.google.com/open?id=1_GXzTuyIopvkkOeCxHanVZKa0tKclD6F"]},{"metadata":{"id":"gP7BoQO-Z6Wk","colab_type":"text"},"cell_type":"markdown","source":["# Data Preprocessing\n"]},{"metadata":{"id":"Us-FmgUYPjH9","colab_type":"text"},"cell_type":"markdown","source":["#### Procedures\n","- Preparation\n","  1. Unzip Data\n","  2. Configurations\n","\n","- Preprocessing\n","  1. Import Data\n","  2. Create Balanced Panel\n","  3. Create Target Variable\n","  4. Scale Data\n","  5. Train / Test Split\n","  6. Create Sequences\n"," "]},{"metadata":{"id":"auT4552tP5dS","colab_type":"text"},"cell_type":"markdown","source":["### Data Description\n","- There are two files, 1. \"coin_price_dfs.csv\" and 2. \"orderbook_dfs.csv\"\n","\n","1. coin_price_dfs.csv\n","  - This dataset includes price (high, low, start, last, volume) for 1 minute interval\n","  - columns\n","    -  timestamp: trading time\n","    - currency: type of currency\n","    - price\n","      - high\n","      - last\n","      - low\n","      - start\n","    - volume: trading volume\n","    \n","2. orderbook_dfs.csv\n"," - This dataset includes order book information for 1 minute interval\n"," - columns\n","    - timestamp: trading time\n","    - ask_price: the lowest price for selling order\n","    - ask_strength [0~99]: each bin contains the volume of ask order in between - 0.1% x (num) ~ - 0.1% x (num+1) from  last price\n","    - bid_price: the highest price for buying order\n","    - bid_stregth [0~99]: each bin contains the volume of bid order in between - 0.1% x (num) ~ - 0.1% x (num+1) from  last price\n","    - currency: type of currency\n","    - bid_ask_spread: spread between ask and bid price"]},{"metadata":{"id":"EnRISOgoh5es","colab_type":"text"},"cell_type":"markdown","source":["## Preparation"]},{"metadata":{"id":"xIxPbmzGQFwR","colab_type":"text"},"cell_type":"markdown","source":["### 1. Data Import and Create Balanced Panel"]},{"metadata":{"id":"4T3G0OFBKcsJ","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TJVHhAmOMWmH","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"796JRrylMW2y","colab_type":"code","colab":{}},"cell_type":"code","source":["DATA_PATH = \"/content/gdrive/My Drive/Lecture/StudyPie/Data/CoinOne/\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"uV7aneomMlG6","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls \"/content/gdrive/My Drive/Lecture/StudyPie/Data/CoinOne/\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"cmkvrXr9MmQ6","colab_type":"code","colab":{}},"cell_type":"code","source":["# Unzip Data\n","# It will take more than 5 min\n","import zipfile\n","import io\n","\n","zf = zipfile.ZipFile(DATA_PATH+\"orderbook_data.zip\", \"r\")\n","zf.extractall(DATA_PATH)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b6KYwPnLrcT-","colab_type":"text"},"cell_type":"markdown","source":["### 2. Configurations"]},{"metadata":{"id":"7KTUsoWxNXqi","colab_type":"code","colab":{}},"cell_type":"code","source":["currency_types = [\"btc\",\"xrp\",\"eth\",\"bch\"]\n","currency_targets = [\"btc\"]\n","\n","TIME_FREQUENCY = 1 # 1, 2, 3, 30 minutes\n","TIME_SEQ_LEN = 60\n","FUTURE_PERIOD_PREDICT = 5\n","\n","# NUM_DEPENDENT_VARIABLE == 2: increase/decrease\n","# NUM_DEPENDENT_VARIABLE == 3: incrase/no change/decrease\n","NUM_DEPENDENT_VARIABLE = 3\n","SIGNIFICANT_CRITERIA = 0.3 # for no change criteria\n","\n","BATCH_SIZE = 128\n","NUM_ITERATIONS = 30\n","\n","TRAIN_RATIO = 0.8"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QI7dLsjor7-x","colab_type":"text"},"cell_type":"markdown","source":["## Preprocessing"]},{"metadata":{"id":"L7faHBekr9WE","colab_type":"text"},"cell_type":"markdown","source":["### 1. Import Data"]},{"metadata":{"id":"p2TejG4LMwkP","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","\n","# read coin price data\n","coin_price_dfs = pd.read_csv(DATA_PATH+\"coin_price_dfs.csv\")\n","# read orderbeook data\n","orderbook_dfs = pd.read_csv(DATA_PATH+\"orderbook_dfs.csv\")    \n","\n","# sort by timestamp\n","coin_price_dfs = coin_price_dfs.sort_values(by=['timestamp','currency'])\n","orderbook_dfs = orderbook_dfs.sort_values(by=['timestamp','currency'])    \n","\n","# select the columns of interests\n","coin_price_dfs = coin_price_dfs[coin_price_dfs[\"currency\"].isin(currency_types)]\n","orderbook_dfs = orderbook_dfs[orderbook_dfs[\"currency\"].isin(currency_types)]\n","\n","print(coin_price_dfs.shape)\n","print(orderbook_dfs.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RdRbZCU-QRXL","colab_type":"text"},"cell_type":"markdown","source":["### 2. Create Balanced Panel"]},{"metadata":{"id":"HchnD0S5siCl","colab_type":"code","colab":{}},"cell_type":"code","source":["coinprice_features = ['currency','last','volume','timestamp']\n","\n","# we only use bid / ask volume data inbetween current price and 3% from it (-3%,-2.9%, =2.8% ...0%, 0.1%, 0.2%... 3%)\n","bid_cols = [\"bid_strength_\"+str(i) for i in range(30)]\n","ask_cols = [\"ask_strength_\"+str(i) for i in range(30)]\n","orderbook_features = bid_cols + ask_cols + [\"currency\",\"timestamp\",\"bid_ask_spread\"]\n","\n","key_features = coinprice_features + orderbook_features\n","\n","# merge price and orderbook data based on timestamp\n","panel_df = pd.merge_asof(left=coin_price_dfs[coinprice_features].reset_index(drop=True), \n","                         right=orderbook_dfs[orderbook_features].reset_index(drop=True),\n","                         on = u'timestamp', by = u'currency')\n","## interpolation\n","panel_df = panel_df.groupby('currency').apply(lambda gp: gp.fillna(method=\"ffill\"))\n","panel_df.dropna(inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vV5_iF7Asj5U","colab_type":"code","colab":{}},"cell_type":"code","source":["panel_df[panel_df['currency']=='btc'].head(n=5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z-htBAvXs3C_","colab_type":"code","colab":{}},"cell_type":"code","source":["# our dataset is not balanced yey\n","# we need to transform dataframe into (timestamp - coin1 - coin2 - coin3 ...)\n","new_panel_df_list = []\n","\n","for currency_type in currency_types:  # begin iteration\n","  new_col_names = {key_feature:currency_type+\"_\"+key_feature \n","                   for key_feature in key_features if key_feature != \"timestamp\"}\n","\n","  single_currency_panel_df = panel_df[panel_df['currency']==currency_type]\n","  single_currency_panel_df.rename(columns=new_col_names, inplace=True)\n","\n","  print(currency_type, \" size: \", single_currency_panel_df.shape[0])    \n","  new_panel_df_list.append(single_currency_panel_df)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5Np4oOfss5Hn","colab_type":"code","colab":{}},"cell_type":"code","source":["balanced_panel_df = new_panel_df_list[0]\n","\n","for new_panel_df in new_panel_df_list[1:]:\n","  balanced_panel_df = pd.merge_asof(left=balanced_panel_df.reset_index(drop=True), \n","                       right=new_panel_df.reset_index(drop=True),\n","                       on = u'timestamp')\n","\n","balanced_panel_df.dropna(inplace=True)    \n","balanced_panel_df.reset_index(drop=True,inplace=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"72h2fiTws7s5","colab_type":"code","colab":{}},"cell_type":"code","source":["balanced_panel_df.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rWipdgFHslhM","colab_type":"text"},"cell_type":"markdown","source":["###   3. Create Target Variable"]},{"metadata":{"id":"G2O-Z_KGsov0","colab_type":"code","colab":{}},"cell_type":"code","source":["# to create target variable we create return \n","for currency_target in currency_targets:\n","  balanced_panel_df[currency_target+'_last_target'] = balanced_panel_df[currency_target+'_last'].shift(-FUTURE_PERIOD_PREDICT )\n","  balanced_panel_df[currency_target+'_last_target_return'] = (balanced_panel_df[currency_target+'_last_target'] \n","                                                              - balanced_panel_df[currency_target+'_last'])/balanced_panel_df[currency_target+'_last']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DLTme-8FtBaH","colab_type":"code","colab":{}},"cell_type":"code","source":["def classify_trinary(values):\n","  gp_std = np.std(values)\n","\n","  target = []\n","  for value in values:\n","    if SIGNIFICANT_CRITERIA*gp_std < value:\n","      target.append(2)\n","    elif -SIGNIFICANT_CRITERIA*gp_std > value:\n","      target.append(0)  \n","    else:\n","      target.append(1)  \n","\n","  return target"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F1avPCaItDag","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","for currency_target in currency_targets:\n","  if NUM_DEPENDENT_VARIABLE == 2:\n","    print(\"NUM_DEPENDENT_VARIABLE: \", 2)\n","    balanced_panel_df[currency_target+'_target'] = balanced_panel_df[currency_target+'_last_target_return'].apply(lambda x: 0 if x <= 0 else 1)\n","\n","  elif NUM_DEPENDENT_VARIABLE == 3:    \n","    print(\"NUM_DEPENDENT_VARIABLE: \", 3)\n","    print(\"SIGNIFICANT_CRITERIA:\", SIGNIFICANT_CRITERIA)\n","    balanced_panel_df[currency_target+'_target'] = balanced_panel_df[currency_target+\"_last_target_return\"].transform(classify_trinary)    \n","\n","  else:\n","    print(\"NUM_DEPENDENT_VARIABLE is not properly specified\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NOl1U87Vtc3c","colab_type":"text"},"cell_type":"markdown","source":["### 4. Scale Data\n","  5. Create Sequences\n","  6. Train / Test Split\n","\n","  \n","\n","- Training / Predicting Model\n","  1. Model Build\n","  2. Model Train\n","  3. Prediction\n","  4. Evaluation <- this assignment implement it"]},{"metadata":{"id":"WECrAHn1teJz","colab_type":"code","colab":{}},"cell_type":"code","source":["# we scaled input data using mix max scaler\n","from sklearn import preprocessing \n","\n","exclude_cols = [] # if you want to ignore some columns for mix max scaling, write the column here\n","exceptions = [\"currency\", \"timestamp\", \"target\"]\n","\n","for col in balanced_panel_df.columns:\n","  exception_occur = False\n","\n","  for exception in exceptions:\n","    if exception in col:\n","      exception_occur = True\n","      exclude_cols.append(col)\n","\n","  if exception_occur:\n","    continue\n","  \n","  balanced_panel_df[col] = preprocessing.minmax_scale(balanced_panel_df[col].values)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m0vrcNhDttOR","colab_type":"code","colab":{}},"cell_type":"code","source":["# we sholud exclude these variable\n","# since we should not predict based on the future information\n","target_cols = [currency_target+\"_target\" for currency_target in currency_targets]\n","\n","for target_col in target_cols:\n","    exclude_cols.remove(target_col) \n","\n","balanced_panel_df = balanced_panel_df.filter(regex=\"^(?!({0})$).*$\".format('|'.join(exclude_cols)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XtS0B2qotvEM","colab_type":"code","colab":{}},"cell_type":"code","source":["balanced_panel_df.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JqnfXndEuSiH","colab_type":"text"},"cell_type":"markdown","source":["### 5. Train / Test Split"]},{"metadata":{"id":"82UhUhYSuUle","colab_type":"code","colab":{}},"cell_type":"code","source":["# split train test dataset\n","panel_df_train = balanced_panel_df.iloc[:int(balanced_panel_df.shape[0]*TRAIN_RATIO)]\n","panel_df_test = balanced_panel_df[~balanced_panel_df.index.isin(panel_df_train.index)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z1nm5ZAAuDOv","colab_type":"text"},"cell_type":"markdown","source":["### 6. Create Sequences"]},{"metadata":{"id":"REgoe3MPuFbv","colab_type":"code","colab":{}},"cell_type":"code","source":["import random\n","from collections import deque\n","\n","def sequence_generator(panel_df, TIME_SEQ_LEN, suffle=True,seed=101):\n","\n","  sequential_data = []  # this is a list that will CONTAIN the sequences\n","  queue = deque(maxlen = TIME_SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n","\n","  for i in panel_df.values:  # iterate over the values\n","    queue.append([n for n in i[:-1]])  # store all but the target\n","    if len(queue) == TIME_SEQ_LEN:  # make sure we have 60 sequences!\n","      sequential_data.append([np.array(queue), i[-1]])  # append those bad boys!\n","\n","  if suffle == True:\n","    random.seed(seed)\n","    random.shuffle(sequential_data)  # shuffle for good measure.\n","\n","  X = []\n","  y = []\n","\n","  for seq, target in sequential_data:  # going over our new sequential data\n","    X.append(seq)  # X is the sequences\n","    y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n","\n","  return np.array(X), y  # return X and y...and make X a numpy array!"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0arExbjMNN--","colab_type":"code","colab":{}},"cell_type":"code","source":["train_X, train_Y = sequence_generator(panel_df_train , TIME_SEQ_LEN, suffle=True, seed=101)\n","test_X, test_Y = sequence_generator(panel_df_test, TIME_SEQ_LEN, suffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nkn_cv6wPVEA","colab_type":"code","colab":{}},"cell_type":"code","source":["print(panel_df_train.shape)\n","print(train_X.shape)\n","print(len(train_Y))\n","\n","print(panel_df_test.shape)\n","print(test_X.shape)\n","print(len(test_Y))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5EUZ0DaTvPg4","colab_type":"text"},"cell_type":"markdown","source":["# Exercise CNN Encoder + RNN Time Series Prediction Model with Limit Orderbook Data"]},{"metadata":{"id":"RHjlJ1Kcu48a","colab_type":"text"},"cell_type":"markdown","source":["- Training / Predicting Model\n","  1. Model Define\n","    - CNN Encoder + RNN Model\n","  2. Model Train\n","  3. Prediction\n","  4. Evaluation <- this assignment implement it"]},{"metadata":{"id":"x_JZcMKHh9xV","colab_type":"text"},"cell_type":"markdown","source":["### 1. Model Build"]},{"metadata":{"id":"0bADWJMbvhfj","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization, Flatten\n","\n","def cnn_encoder_lstm(input_dim, output_dim):\n","    \n","  \"\"\"\n","  Write Code Here!!!\n","  \n","  Implemenent 1D Conv along the time dimension  \n","  \n","  Refer our Hands-on-Labs code\n","  \"\"\"\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2xtMiiEMiJ-N","colab_type":"code","colab":{}},"cell_type":"code","source":["model_dict = {}\n","model_dict[\"CNN_ENCODER_LSTM\"] = cnn_encoder_lstm(train_X.shape[1:], NUM_DEPENDENT_VARIABLE)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8xHSWzs8iBq1","colab_type":"text"},"cell_type":"markdown","source":["### 2. Model Train\n"]},{"metadata":{"id":"XlwicNBhiFSt","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 64 \n","NUM_ITERATIONS = 10\n","\n","hist = {}\n","\n","for name, model in model_dict.items():\n","\n","  print(\"===== Model Name: {} =====\".format(name))    \n","  if name == \"CNN_ENCODER_LSTM\":\n","    hist[name] = model.fit(train_X.reshape(-1, train_X.shape[1:][0], train_X.shape[1:][1]),\n","                          tf.keras.utils.to_categorical(train_Y, num_classes=None), \n","                          batch_size = BATCH_SIZE,\n","                          validation_split=0.2,\n","                          epochs = NUM_ITERATIONS)\n","\n","  print(\"===== Train Done =====\".format(name))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Sjk0WzkeiDV9","colab_type":"text"},"cell_type":"markdown","source":["### 3. Prediction"]},{"metadata":{"id":"IZS3dLzDiEjk","colab_type":"code","colab":{}},"cell_type":"code","source":["predictions = {}\n","\n","for name, model in model_dict.items():  \n","  print(\"===== Model Name: {} =====\".format(name))  \n","  if name == \"CNN_ENCODER_LSTM\":\n","    predictions[name] = model.predict_classes(test_X.reshape(-1, train_X.shape[1:][0], train_X.shape[1:][1]))\n","\n","  else:\n","    predictions[name] = model.predict_classes(test_X)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gpMXFCmJWpGn","colab_type":"text"},"cell_type":"markdown","source":["### 4. Evaluation"]},{"metadata":{"id":"W4fg4LpdrNwp","colab_type":"text"},"cell_type":"markdown","source":["1. Comparing Accuracy both Train and Validation set data\n","  - Compare loss according to the below materials\n","  - Visualize training history  \n","  - Check genelarization of your model\n","  - Refer\n","    - https://medium.com/machine-learning-world/neural-networks-for-algorithmic-trading-1-2-correct-time-series-forecasting-backtesting-9776bfd9e589\n","  - Visualization Hint\n","    - https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"]},{"metadata":{"id":"vyS_lAOOrJYm","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.title('model loss')\n","legend_names = []\n","# summarize history for accuracy\n","for name, model_hist in hist.items():\n","  plt.plot(model_hist.history['loss'])\n","  plt.plot(model_hist.history['val_loss'])\n","  legend_names.extend([name+'_train', name+'_validation'])\n","  \n","plt.legend(legend_names, loc='upper left')\n","\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_GGcnPYLrguk","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.title('model acc')\n","legend_names = []\n","# summarize history for accuracy\n","for name, model_hist in hist.items():\n","  plt.plot(model_hist.history['acc'])\n","  plt.plot(model_hist.history['val_acc'])\n","  legend_names.extend([name+'_train', name+'_validation'])\n","  \n","plt.legend(legend_names, loc='upper left')\n","\n","plt.ylabel('acc')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kZFhS-1Ubhp7","colab_type":"text"},"cell_type":"markdown","source":["2. Measure Model Accuracy for Classification Problem\n","  - Now we are going to evaluate our model \n","  - Accuracy, Recall, F1 Score based on Confusion Matrix\n","  - Refer definition of each scores\n","    - Confusion matrix https://en.wikipedia.org/wiki/Confusion_matrix\n","    - Confusion matrix in Korean https://datascienceschool.net/view-notebook/731e0d2ef52c41c686ba53dcaf346f32/\n","    \n","  - Hint\n","    - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n","    - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"]},{"metadata":{"id":"ZgL9kC2zbj5o","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","for name, prediction_model in predictions.items():\n","  print(\"===== Model Name: {} =====\".format(name))  \n","  print(classification_report(prediction_model, test_Y))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FJLMnCarxKuf","colab_type":"text"},"cell_type":"markdown","source":["3. Measure Test Set Return based on the Simplest Strategy\n","  - Condition\n","    - Initial budget = 100\n"," - Strategy\n","    - If we predict up, then buy or hold (if we already bought)\n","    - If we predict down or no change then sell (if we already bought) or do nothing \n","  - Draw your return"]},{"metadata":{"id":"ru67SM1hxKVW","colab_type":"code","colab":{}},"cell_type":"code","source":["for name, prediction_model in predictions.items():\n","  print(\"===== Model Name: {} =====\".format(name))  \n","  \n","  for currency_target in currency_targets:\n","      bechmark_return = 100\n","      bechmark_return_history = []\n","\n","      prediction_return = 100\n","      prediction_return_history = []\n","\n","      buy_price = 0\n","      sell_price = 0\n","\n","      hold = False\n","\n","      panel_df_test[currency_target+'_last_return'] = panel_df_test[currency_target+'_last'].pct_change()\n","      \n","      for prediction, (i, r) in zip(prediction_model, panel_df_test.iloc[TIME_SEQ_LEN-1:].iterrows()):\n","\n","          if hold == True:\n","              prediction_return = prediction_return*(1+r[currency_target+'_last_return'])  \n","\n","          bechmark_return = bechmark_return*(1+r[currency_target+'_last_return'])\n","          bechmark_return_history.append(bechmark_return)\n","          prediction_return_history.append(prediction_return)\n","\n","          if prediction ==2:\n","              hold = True\n","          else: \n","              hold = False\n","\n","      plt.title(currency_target)\n","      plt.plot(prediction_return_history, label = name+' prediction return')    \n","      plt.plot(bechmark_return_history, label = 'becnmark return')\n","      plt.xticks(rotation=30)\n","      plt.legend()\n","      plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"e3SCGrXaqV-p","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}