{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab_Hyperparamter_tuning.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"G1CLeL2q68gI","colab_type":"text"},"cell_type":"markdown","source":["# Hyperparameter tuning"]},{"metadata":{"id":"TW1mvJM17IE1","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","import tensorflow as tf  # deep learning library. Tensors are just multi-dimensional arrays\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aYovY1PK7WAw","colab_type":"text"},"cell_type":"markdown","source":["## Data Import"]},{"metadata":{"id":"YiaKyTYP7KUE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"c7c3a0c7-81d8-427c-a964-4fcc5fb8a5f4","executionInfo":{"status":"ok","timestamp":1541623622952,"user_tz":-540,"elapsed":1460,"user":{"displayName":"Jongho Kim","photoUrl":"","userId":"01418265235228620365"}}},"cell_type":"code","source":["mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n","(x_train, y_train),(x_test, y_test) = mnist.load_data()  # unpacks images to x_train/x_test and labels to y_train/y_test"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"Xzwvjuka7Ydx","colab_type":"code","colab":{}},"cell_type":"code","source":["x_train = tf.keras.utils.normalize(x_train, axis=1)  # scales data between 0 and 1\n","x_test = tf.keras.utils.normalize(x_test, axis=1)  # scales data between 0 and 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oNxXKoTh7aRi","colab_type":"text"},"cell_type":"markdown","source":["## Compare Learning Rates"]},{"metadata":{"id":"zpgWCeHE7cT4","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.keras.optimizers import SGD\n","\n","dflist = []\n","\n","learning_rates = [0.01, 0.05, 0.1, 0.5]\n","\n","for lr in learning_rates:\n","\n","  K.clear_session()\n","\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n","  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n","  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n","  model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n","\n","  model.compile(optimizer=SGD(lr=lr),  # Good default optimizer to start with\n","                loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n","                metrics=['accuracy'])  # what to track\n","\n","  h =  model.fit(x_train, y_train, batch_size=16, verbose=0)  \n","\n","  dflist.append(pd.DataFrame(h.history, index=h.epoch))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0H51l_jm8uEX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ea930cb5-399d-4c2a-d359-aa4653d73e22","executionInfo":{"status":"ok","timestamp":1541623969623,"user_tz":-540,"elapsed":619,"user":{"displayName":"Jongho Kim","photoUrl":"","userId":"01418265235228620365"}}},"cell_type":"code","source":["h.history.keys()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['loss', 'acc'])"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"gf9ZdhFx7sJS","colab_type":"code","colab":{}},"cell_type":"code","source":["historydf = pd.concat(dflist, axis=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s93RIFcG7gdB","colab_type":"code","colab":{}},"cell_type":"code","source":["metrics_reported = dflist[0].columns\n","idx = pd.MultiIndex.from_product([learning_rates, metrics_reported],\n","                                 names=['learning_rate', 'metric'])\n","\n","historydf.columns = idx"],"execution_count":0,"outputs":[]},{"metadata":{"id":"q8LH8r7s8126","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"outputId":"686fc1b2-b74a-4b77-d6ea-628325c2a1fb","executionInfo":{"status":"ok","timestamp":1541624048056,"user_tz":-540,"elapsed":657,"user":{"displayName":"Jongho Kim","photoUrl":"","userId":"01418265235228620365"}}},"cell_type":"code","source":["historydf"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th>learning_rate</th>\n","      <th colspan=\"2\" halign=\"left\">0.01</th>\n","      <th colspan=\"2\" halign=\"left\">0.05</th>\n","      <th colspan=\"2\" halign=\"left\">0.10</th>\n","      <th colspan=\"2\" halign=\"left\">0.50</th>\n","    </tr>\n","    <tr>\n","      <th>metric</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.81235</td>\n","      <td>0.741103</td>\n","      <td>0.8938</td>\n","      <td>0.367638</td>\n","      <td>0.912683</td>\n","      <td>0.292995</td>\n","      <td>0.92175</td>\n","      <td>0.259577</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["learning_rate     0.01              0.05                0.10            \\\n","metric             acc      loss     acc      loss       acc      loss   \n","0              0.81235  0.741103  0.8938  0.367638  0.912683  0.292995   \n","\n","learning_rate     0.50            \n","metric             acc      loss  \n","0              0.92175  0.259577  "]},"metadata":{"tags":[]},"execution_count":23}]},{"metadata":{"id":"zdHAw21y7jFo","colab_type":"text"},"cell_type":"markdown","source":["## Batch Size"]},{"metadata":{"id":"F3Oqw_uu7luh","colab_type":"code","colab":{}},"cell_type":"code","source":["dflist = []\n","\n","batch_sizes = [16, 32, 64, 128]\n","\n","for batch_size in batch_sizes:\n","  K.clear_session()\n","\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n","  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n","  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n","  model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n","\n","  model.compile(optimizer='sgd',  # Good default optimizer to start with\n","                loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n","                metrics=['accuracy'])  # what to track\n","\n","  h =  model.fit(x_train, y_train, batch_size=batch_size, verbose=0)  \n","\n","  dflist.append(pd.DataFrame(h.history, index=h.epoch))  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"oYng3HBE9aik","colab_type":"code","colab":{}},"cell_type":"code","source":["historydf = pd.concat(dflist, axis=1)\n","metrics_reported = dflist[0].columns\n","idx = pd.MultiIndex.from_product([batch_sizes, metrics_reported],\n","                                 names=['batch_size', 'metric'])\n","historydf.columns = idx"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hhWMLcct9bid","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"outputId":"8a60b51d-93b1-4484-cf31-9cc014149f75","executionInfo":{"status":"ok","timestamp":1541624168029,"user_tz":-540,"elapsed":657,"user":{"displayName":"Jongho Kim","photoUrl":"","userId":"01418265235228620365"}}},"cell_type":"code","source":["historydf"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th>batch_size</th>\n","      <th colspan=\"2\" halign=\"left\">16</th>\n","      <th colspan=\"2\" halign=\"left\">32</th>\n","      <th colspan=\"2\" halign=\"left\">64</th>\n","      <th colspan=\"2\" halign=\"left\">128</th>\n","    </tr>\n","    <tr>\n","      <th>metric</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.805883</td>\n","      <td>0.758128</td>\n","      <td>0.739983</td>\n","      <td>1.078245</td>\n","      <td>0.613867</td>\n","      <td>1.606198</td>\n","      <td>0.46</td>\n","      <td>2.013939</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["batch_size       16                  32                  64              128  \\\n","metric           acc      loss       acc      loss       acc      loss   acc   \n","0           0.805883  0.758128  0.739983  1.078245  0.613867  1.606198  0.46   \n","\n","batch_size            \n","metric          loss  \n","0           2.013939  "]},"metadata":{"tags":[]},"execution_count":30}]},{"metadata":{"id":"PvtJZcqo9cRt","colab_type":"text"},"cell_type":"markdown","source":["## Optimizers"]},{"metadata":{"id":"Re3tla6W9fQ9","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.keras.optimizers import SGD, Adam, Adagrad, RMSprop"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1iHWN0jS9hVt","colab_type":"code","colab":{}},"cell_type":"code","source":["dflist = []\n","\n","optimizers = ['SGD(lr=0.01)',\n","              'SGD(lr=0.01, momentum=0.3)',\n","              'SGD(lr=0.01, momentum=0.3, nesterov=True)',  \n","              'Adam(lr=0.01)',\n","              'Adagrad(lr=0.01)',\n","              'RMSprop(lr=0.01)']\n","\n","for opt_name in optimizers:\n","\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n","  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n","  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n","  model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n","\n","  model.compile(optimizer=eval(opt_name),  # Good default optimizer to start with\n","                loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n","                metrics=['accuracy'])  # what to track\n","\n","  h =  model.fit(x_train, y_train, batch_size=16, verbose=0, epochs=5)  \n","\n","  dflist.append(pd.DataFrame(h.history, index=h.epoch))     "],"execution_count":0,"outputs":[]},{"metadata":{"id":"1EUs4g8E9o_8","colab_type":"code","colab":{}},"cell_type":"code","source":["historydf = pd.concat(dflist, axis=1)\n","metrics_reported = dflist[0].columns\n","idx = pd.MultiIndex.from_product([optimizers, metrics_reported],\n","                                 names=['optimizers', 'metric'])\n","historydf.columns = idx"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KVvXFudm9qca","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"outputId":"51943a83-a293-4c47-91e3-1c307a815a90","executionInfo":{"status":"ok","timestamp":1541624270441,"user_tz":-540,"elapsed":653,"user":{"displayName":"Jongho Kim","photoUrl":"","userId":"01418265235228620365"}}},"cell_type":"code","source":["historydf"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th>optimizers</th>\n","      <th colspan=\"2\" halign=\"left\">SGD(lr=0.01)</th>\n","      <th colspan=\"2\" halign=\"left\">SGD(lr=0.01, momentum=0.3)</th>\n","      <th colspan=\"2\" halign=\"left\">SGD(lr=0.01, momentum=0.3, nesterov=True)</th>\n","      <th colspan=\"2\" halign=\"left\">Adam(lr=0.01)</th>\n","      <th colspan=\"2\" halign=\"left\">Adagrad(lr=0.01)</th>\n","      <th colspan=\"2\" halign=\"left\">RMSprop(lr=0.01)</th>\n","    </tr>\n","    <tr>\n","      <th>metric</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.800367</td>\n","      <td>0.787923</td>\n","      <td>0.832383</td>\n","      <td>0.630575</td>\n","      <td>0.84125</td>\n","      <td>0.619871</td>\n","      <td>0.91785</td>\n","      <td>0.290038</td>\n","      <td>0.92875</td>\n","      <td>0.240809</td>\n","      <td>0.91375</td>\n","      <td>0.414608</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["optimizers SGD(lr=0.01)           SGD(lr=0.01, momentum=0.3)            \\\n","metric              acc      loss                        acc      loss   \n","0              0.800367  0.787923                   0.832383  0.630575   \n","\n","optimizers SGD(lr=0.01, momentum=0.3, nesterov=True)           Adam(lr=0.01)  \\\n","metric                                           acc      loss           acc   \n","0                                            0.84125  0.619871       0.91785   \n","\n","optimizers           Adagrad(lr=0.01)           RMSprop(lr=0.01)            \n","metric          loss              acc      loss              acc      loss  \n","0           0.290038          0.92875  0.240809          0.91375  0.414608  "]},"metadata":{"tags":[]},"execution_count":34}]},{"metadata":{"id":"dD_mMo769r1D","colab_type":"text"},"cell_type":"markdown","source":["## Initialization"]},{"metadata":{"id":"SNSzjk-59wXc","colab_type":"code","colab":{}},"cell_type":"code","source":["dflist = []\n","\n","initializers = ['zeros', 'uniform', 'normal',\n","                'he_normal', 'lecun_uniform']\n","\n","for init in initializers:\n","\n","  K.clear_session()\n","\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n","  model.add(tf.keras.layers.Dense(128, kernel_initializer=init, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n","  model.add(tf.keras.layers.Dense(128, kernel_initializer=init, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n","  model.add(tf.keras.layers.Dense(10, kernel_initializer=init, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n","\n","  model.compile(optimizer='rmsprop',  # Good default optimizer to start with\n","                loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n","                metrics=['accuracy'])  # what to track\n","\n","  h =  model.fit(x_train, y_train, batch_size=16, verbose=0, epochs=5)  \n","\n","  \n","  dflist.append(pd.DataFrame(h.history, index=h.epoch))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DzTZ-geS-BBR","colab_type":"code","colab":{}},"cell_type":"code","source":["historydf = pd.concat(dflist, axis=1)\n","metrics_reported = dflist[0].columns\n","idx = pd.MultiIndex.from_product([initializers, metrics_reported],\n","                                 names=['initializers', 'metric'])\n","\n","historydf.columns = idx"],"execution_count":0,"outputs":[]},{"metadata":{"id":"404iTWdW-B55","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"outputId":"346816bd-3ee7-4759-c266-dff45aeb98df","executionInfo":{"status":"ok","timestamp":1541624362267,"user_tz":-540,"elapsed":728,"user":{"displayName":"Jongho Kim","photoUrl":"","userId":"01418265235228620365"}}},"cell_type":"code","source":["historydf"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th>initializers</th>\n","      <th colspan=\"2\" halign=\"left\">zeros</th>\n","      <th colspan=\"2\" halign=\"left\">uniform</th>\n","      <th colspan=\"2\" halign=\"left\">normal</th>\n","      <th colspan=\"2\" halign=\"left\">he_normal</th>\n","      <th colspan=\"2\" halign=\"left\">lecun_uniform</th>\n","    </tr>\n","    <tr>\n","      <th>metric</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.111767</td>\n","      <td>2.301561</td>\n","      <td>0.910033</td>\n","      <td>0.302547</td>\n","      <td>0.919583</td>\n","      <td>0.274092</td>\n","      <td>0.92925</td>\n","      <td>0.24182</td>\n","      <td>0.923467</td>\n","      <td>0.252066</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["initializers     zeros             uniform              normal            \\\n","metric             acc      loss       acc      loss       acc      loss   \n","0             0.111767  2.301561  0.910033  0.302547  0.919583  0.274092   \n","\n","initializers he_normal          lecun_uniform            \n","metric             acc     loss           acc      loss  \n","0              0.92925  0.24182      0.923467  0.252066  "]},"metadata":{"tags":[]},"execution_count":37}]},{"metadata":{"id":"ZmlNK_-k-g1H","colab_type":"text"},"cell_type":"markdown","source":["## Batch Normalization"]},{"metadata":{"id":"r-YEkXkT-idc","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.keras.layers import BatchNormalization"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cubZ0rQe-mBt","colab_type":"code","colab":{}},"cell_type":"code","source":["def repeated_training(x_train,\n","                      y_train,\n","                      x_test,\n","                      y_test,\n","                      do_bn=False,\n","                      epochs=5,\n","                      repeats=3):\n","  histories = []\n","\n","  for repeat in range(repeats):\n","    K.clear_session()\n","\n","    model = tf.keras.models.Sequential()\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.Dense(128, kernel_initializer='normal', activation=tf.nn.relu))\n","\n","    if do_bn:\n","        model.add(BatchNormalization())\n","        \n","    model.add(tf.keras.layers.Dense(128, kernel_initializer='normal', activation=tf.nn.relu))\n","      \n","    if do_bn:\n","        model.add(BatchNormalization())\n","\n","    model.add(tf.keras.layers.Dense(10, kernel_initializer=init, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n","    \n","    model.compile(optimizer='rmsprop',  # Good default optimizer to start with\n","                  loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n","                  metrics=['accuracy'])  # what to track\n","\n","    h = model.fit(x_train, y_train,\n","                  validation_data=(x_test, y_test),\n","                  epochs=epochs,\n","                  verbose=0)\n","    \n","    histories.append([h.history['acc'], h.history['val_acc']])\n","    print(repeat, end=' ')\n","\n","  histories = np.array(histories)\n","\n","  # calculate mean and standard deviation across repeats:\n","  mean_acc = histories.mean(axis=0)\n","  std_acc = histories.std(axis=0)\n","  print()\n","\n","  return mean_acc[0], std_acc[0], mean_acc[1], std_acc[1]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MoxsGh8AAD02","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"fd9c9e6f-056e-4ee0-87b9-f91d3458ffbe","executionInfo":{"status":"ok","timestamp":1541624957866,"user_tz":-540,"elapsed":96164,"user":{"displayName":"Jongho Kim","photoUrl":"","userId":"01418265235228620365"}}},"cell_type":"code","source":["mean_acc, std_acc, mean_acc_val, std_acc_val = \\\n","    repeated_training(x_train, y_train, x_test, y_test, do_bn=False)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["0 1 2 \n"],"name":"stdout"}]},{"metadata":{"id":"-3mNieHxAHE-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"92733b35-2e23-4b03-f71d-073e9282d183","executionInfo":{"status":"ok","timestamp":1541625051485,"user_tz":-540,"elapsed":93604,"user":{"displayName":"Jongho Kim","photoUrl":"","userId":"01418265235228620365"}}},"cell_type":"code","source":["mean_acc_bn, std_acc_bn, mean_acc_val_bn, std_acc_val_bn = \\\n","    repeated_training(x_train, y_train, x_test, y_test, do_bn=True)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["0 1 2 \n"],"name":"stdout"}]},{"metadata":{"id":"rWLQyScgAJWl","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_mean_std(m, s):\n","    plt.plot(m)\n","    plt.fill_between(range(len(m)), m-s, m+s, alpha=0.1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HQasvnd1AKld","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":311},"outputId":"dd3f76cd-6d9d-4647-e75e-98be62f6cf60","executionInfo":{"status":"ok","timestamp":1541625053328,"user_tz":-540,"elapsed":1038,"user":{"displayName":"Jongho Kim","photoUrl":"","userId":"01418265235228620365"}}},"cell_type":"code","source":["plot_mean_std(mean_acc, std_acc)\n","plot_mean_std(mean_acc_val, std_acc_val)\n","plot_mean_std(mean_acc_bn, std_acc_bn)\n","plot_mean_std(mean_acc_val_bn, std_acc_val_bn)\n","plt.ylim(0, 1.01)\n","plt.title(\"Batch Normalization Accuracy\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend(['Train', 'Test', 'Train with Batch Normalization', 'Test with Batch Normalization'], loc='best')\n"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f14e455ccf8>"]},"metadata":{"tags":[]},"execution_count":43},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n","text/plain":["<matplotlib.figure.Figure at 0x7f14e2755940>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"I_ZEbLqFAL8U","colab_type":"text"},"cell_type":"markdown","source":["## Weight Regularization & Dropout"]},{"metadata":{"id":"uqpguOtXAU8s","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.keras.layers import Dropout\n","\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n","model.add(Dropout(0.2))\n","model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n","model.add(Dropout(0.2))\n","model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n","model.add(Dropout(0.2))\n","\n","model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n","\n","model.compile(optimizer='rmsprop',  # Good default optimizer to start with\n","              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n","              metrics=['accuracy'])  # what to track"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IcMLs7J7BIzu","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}